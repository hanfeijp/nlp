{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REFERENCES\n",
    "\n",
    "* http://www.aic.uniovi.es/~jdiez/Jorge_Diez/Journal_Papers_files/luaces2012a.pdf\n",
    "\n",
    "# AIM\n",
    "\n",
    "文章データ（日本語）をBinary Relevanceの方法でマルチラベル分類を行う  \n",
    "２値分類器にはナイーブベイズ分類を使う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "matplotlib.style.use(\"ggplot\")\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python 3.5.2\n",
      "\n",
      "numpy 1.13.1\n",
      "matplotlib 2.0.2\n",
      "scikit-learn 0.19.0\n",
      "mecab-python3 0.7\n"
     ]
    }
   ],
   "source": [
    "from pkg_resources import get_distribution\n",
    "import platform\n",
    "print(\"python\", platform.python_version())\n",
    "print(\"\")\n",
    "libs = [\"numpy\", \"matplotlib\", \"scikit-learn\", \"mecab-python3\"]\n",
    "for lib in libs:\n",
    "    version = get_distribution(lib).version\n",
    "    print(lib, version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 正例と負例のみを与えて学習させるようにする\n",
    "class BinaryRelevance:\n",
    "    def __init__(self, corpus):\n",
    "        # クラスの初期化\n",
    "        # :param corpus (string(object) np.array): コーパス\n",
    "        self.labels = [] # 分類ラベルリスト\n",
    "        self.clfs = {} # 分類器インスタンスリスト\n",
    "        # MeCab\n",
    "        self.index_category = 0\n",
    "        self.index_root_form = 6\n",
    "        self.target_categories = [\"名詞\", \"動詞\", \"形容詞\", \"副詞\", \"連体詞\", \"感動詞\"]\n",
    "        self.stop_words = []\n",
    "        self.mecab = MeCab.Tagger()\n",
    "        # Vectorizer\n",
    "        self.vectorizer = CountVectorizer(binary=True, analyzer=self.analyzer) # BoW, binary\n",
    "        self.vectorizer.fit_transform(corpus)\n",
    "        \n",
    "    def analyzer(self, text):\n",
    "        # 形態素解析を行う\n",
    "        # :param text (string): 文章\n",
    "        # :return:\n",
    "        if not text:\n",
    "            return []\n",
    "        words = []\n",
    "        node = self.mecab.parseToNode(text)\n",
    "        while node:\n",
    "            word = \"\"\n",
    "            features = node.feature.split(\",\")\n",
    "            if features[self.index_category] in self.target_categories:\n",
    "                if features[self.index_root_form] == \"*\":\n",
    "                    word = node.surface\n",
    "                else:\n",
    "                    word = features[self.index_root_form]\n",
    "            if len(word) > 0 and word not in self.stop_words:\n",
    "                words.append(word)\n",
    "            node = node.next\n",
    "        return words\n",
    "        \n",
    "    def train(self, target_label, positive_x, negative_x):\n",
    "        # 学習\n",
    "        # :param target_label (int): どのラベルの分類器を学習させるか\n",
    "        # :param positive_x (string(object) np.array): 正例の文章リスト\n",
    "        # :param negative_x (string(object) np.array): 負例の文章リスト\n",
    "        # エラーチェック\n",
    "        if not self.exists_label(target_label):\n",
    "            return False\n",
    "        # ペアデータセットにしてシャッフルする\n",
    "        dataset = []\n",
    "        for x in positive_x:\n",
    "            dataset.append((x,1)) # 正例\n",
    "        for x in negative_x:\n",
    "            dataset.append((x,0)) # 負例\n",
    "        dataset = np.array(dataset)\n",
    "        np.random.shuffle(dataset) # シャッフル\n",
    "        x = np.array(dataset[:,0], dtype=\"object\") # 入力\n",
    "        y = np.array(dataset[:,1], dtype=\"int32\") # ラベル\n",
    "        self.clfs[target_label].fit(self.vectorizer.transform(x), y) # 学習            \n",
    "        return True\n",
    "    \n",
    "    def predict(self, x):\n",
    "        # 予測\n",
    "        # :param x: 予測させる文章リスト\n",
    "        # :return: \n",
    "        result = []\n",
    "        for i in range(len(x)):\n",
    "            result.append([]) # 付与されたラベルを追加していくための配列\n",
    "        for label in self.clfs: # 分類器をループ\n",
    "            y = self.clfs[label].predict(self.vectorizer.transform(x)) # このラベルかどうかを予測\n",
    "            for i, y_ in enumerate(y):\n",
    "                if y_ == 1: # このラベルがつくと予想された\n",
    "                    result[i].append(label)\n",
    "        return result\n",
    "        \n",
    "    def set_labels(self, labels):\n",
    "        # ラベルとラベルに対応する分類器インスタンスをセットする\n",
    "        # :params labels (int np.array): 追加するラベルリスト\n",
    "        for label in labels:\n",
    "            self.labels.append(label) # ラベル追加\n",
    "            self.clfs[label] = MultinomialNB(alpha=1.0) # 分類器インスタンス作成\n",
    "    \n",
    "    def exists_label(self, label):\n",
    "        # ラベルが存在するかどうか\n",
    "        # :param label (int): 調べるラベル\n",
    "        if (label not in self.labels) or (label not in self.clfs):\n",
    "            return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2], [0, 1, 2], [2], [0, 1], [0, 1], [0, 1, 2], [2], [0, 1], [0, 1, 2], [0, 1], [2], [0, 1], [0, 1], [0, 1], [2], [0, 1], [0, 1], [0, 1, 2], [0, 2], [2], [0, 1, 2], [0, 1], [0, 1], [0, 1], [2], [0, 1], [0, 1, 2], [0, 1], [0, 1], [2], [0, 1], [2], [0, 1, 2], [0, 1], [2], [0, 1], [0, 1], [0, 1], [0, 1, 2], [2], [2], [2], [2], [0, 1], [0, 1], [2], [2], [0, 1], [0, 1, 2], [0, 1, 2], [0, 1], [0, 1], [2], [0, 1], [2], [0, 1], [0, 1], [0, 1], [2], [1, 2], [0, 1, 2], [0, 1], [0, 1], [0, 1], [2], [0, 1], [0, 2], [0, 1, 2], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [2], [2], [2], [0, 1, 2], [0, 1], [0, 1, 2], [0, 1, 2], [2], [2], [0, 1], [0, 1], [0, 1], [0, 1], [0, 2], [0, 1], [0, 1], [2], [0, 1], [0, 1], [0, 1], [0, 1, 2], [2], [0, 1], [2], [0, 1], [0, 1], [0, 1, 2]]\n"
     ]
    }
   ],
   "source": [
    "path = \"./livedoor_news_corpus/text\"\n",
    "categories = [\"it-life-hack\", \"kaden-channel\", \"sports-watch\"]\n",
    "data = []\n",
    "for category in categories:\n",
    "    files = glob.glob(path + \"/\" + category + \"/\" + category + \"*\")\n",
    "    for file in files:\n",
    "        f = open(file)\n",
    "        data.append((f.read(), categories.index(category))) # ファイルの中身、カテゴリーラベル\n",
    "        f.close()\n",
    "# ファイルの中身が、URL、日付、タイトル、本文と含んでいるので、本文のみにする\n",
    "data_tmp = []\n",
    "for d in data:\n",
    "    x, t = d[0], d[1] # ファイルの中身、カテゴリーラベル\n",
    "    x = x.split(\"\\n\")\n",
    "    x = x[3:] # URL、日付、タイトルを落とす\n",
    "    x = \" \".join(x)\n",
    "    data_tmp.append((x, t)) # 本文、カテゴリーラベル\n",
    "data = data_tmp\n",
    "data = np.array(data)\n",
    "np.random.shuffle(data)\n",
    "br = BinaryRelevance(data[:,0].tolist())\n",
    "br.set_labels([0,1,2])\n",
    "\n",
    "train0, train1, train2 = [], [], []\n",
    "for d in data:\n",
    "    x, t = d[0], int(d[1])\n",
    "    if t == 0:\n",
    "        train0.append(x)\n",
    "    elif t == 1:\n",
    "        train1.append(x)\n",
    "    elif t == 2:\n",
    "        train2.append(x)\n",
    "train0, train1, tarin2 = train0[:N], train1[:N], train2[:N]\n",
    "\n",
    "negative_x = np.array(train1+train2)\n",
    "np.random.shuffle(negative_x)\n",
    "negative_x = negative_x[:N]\n",
    "br.train(0, train0, negative_x)\n",
    "\n",
    "negative_x = np.array(train0+train2)\n",
    "np.random.shuffle(negative_x)\n",
    "negative_x = negative_x[:N]\n",
    "br.train(1, train1, negative_x)\n",
    "\n",
    "negative_x = np.array(train0+train1)\n",
    "np.random.shuffle(negative_x)\n",
    "negative_x = negative_x[:N]\n",
    "br.train(2, train2, negative_x)\n",
    "\n",
    "y = br.predict(data[:,0][-100:])\n",
    "print(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
