{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REFERENCES\n",
    "\n",
    "* http://www.aic.uniovi.es/~jdiez/Jorge_Diez/Journal_Papers_files/luaces2012a.pdf\n",
    "\n",
    "# AIM\n",
    "\n",
    "文章データをBinary Relevanceの方法でマルチラベル分類を行う  \n",
    "２値分類器にはナイーブベイズ分類を使う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "matplotlib.style.use(\"ggplot\")\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python 3.5.2\n",
      "\n",
      "numpy 1.13.1\n",
      "matplotlib 2.0.2\n",
      "scikit-learn 0.19.0\n"
     ]
    }
   ],
   "source": [
    "from pkg_resources import get_distribution\n",
    "import platform\n",
    "print(\"python\", platform.python_version())\n",
    "print(\"\")\n",
    "libs = [\"numpy\", \"matplotlib\", \"scikit-learn\"]\n",
    "for lib in libs:\n",
    "    version = get_distribution(lib).version\n",
    "    print(lib, version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 正例と負例のみを与えて学習させるようにする\n",
    "class BinaryRelevance:\n",
    "    def __init__(self, corpus):\n",
    "        # クラスの初期化\n",
    "        # :param corpus (string(object) np.array): コーパス\n",
    "        self.labels = [] # 分類ラベルリスト\n",
    "        self.clfs = {} # 分類器インスタンスリスト\n",
    "        # set vectorizer\n",
    "        self.vectorizer = CountVectorizer(binary=True) # BoW, binary\n",
    "        self.vectorizer.fit_transform(corpus)\n",
    "        \n",
    "    def train(self, target_label, positive_x, negative_x):\n",
    "        # 学習\n",
    "        # :param target_label (int): どのラベルの分類器を学習させるか\n",
    "        # :param positive_x (string(object) np.array): 正例の文章リスト\n",
    "        # :param negative_x (string(object) np.array): 負例の文章リスト\n",
    "        # エラーチェック\n",
    "        if not self.exists_label(target_label):\n",
    "            return False\n",
    "        # ペアデータセットにしてシャッフルする\n",
    "        dataset = []\n",
    "        for x in positive_x:\n",
    "            dataset.append((x,1)) # 正例\n",
    "        for x in negative_x:\n",
    "            dataset.append((x,0)) # 負例\n",
    "        dataset = np.array(dataset)\n",
    "        np.random.shuffle(dataset) # シャッフル\n",
    "        x = np.array(dataset[:,0], dtype=\"object\") # 入力\n",
    "        y = np.array(dataset[:,1], dtype=\"int32\") # ラベル\n",
    "        self.clfs[target_label].fit(self.vectorizer.transform(x), y) # 学習            \n",
    "        return True\n",
    "    \n",
    "    def predict(self, x):\n",
    "        # 予測\n",
    "        # :param x: 予測させる文章リスト\n",
    "        # :return: \n",
    "        result = []\n",
    "        for i in range(len(x)):\n",
    "            result.append([]) # 付与されたラベルを追加していくための配列\n",
    "        for label in self.clfs: # 分類器をループ\n",
    "            y = self.clfs[label].predict(self.vectorizer.transform(x)) # このラベルかどうかを予測\n",
    "            for i, y_ in enumerate(y):\n",
    "                if y_ == 1: # このラベルがつくと予想された\n",
    "                    result[i].append(label)\n",
    "        return result\n",
    "        \n",
    "    def set_labels(self, labels):\n",
    "        # ラベルとラベルに対応する分類器インスタンスをセットする\n",
    "        # :params labels (int np.array): 追加するラベルリスト\n",
    "        for label in labels:\n",
    "            self.labels.append(label) # ラベル追加\n",
    "            self.clfs[label] = MultinomialNB(alpha=1.0) # 分類器インスタンス作成\n",
    "    \n",
    "    def exists_label(self, label):\n",
    "        # ラベルが存在するかどうか\n",
    "        # :param label (int): 調べるラベル\n",
    "        if (label not in self.labels) or (label not in self.clfs):\n",
    "            return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 2], [2], [0, 2], [0, 1, 2], [0, 2], [2], [2], [0, 2], [0, 2], [2], [0, 2], [2], [0, 2], [0, 1, 2], [0, 2], [0, 1, 2], [0, 2], [0, 2], [0, 1, 2], [2], [0, 2], [2], [0, 1, 2], [0, 2], [0, 1, 2], [1, 2], [0, 2], [0, 1, 2], [0, 2], [0, 1, 2], [0, 1, 2], [2], [1, 2], [0, 2], [0, 2], [0, 2], [0, 2], [0, 2], [0, 2], [2], [0, 2], [2], [0, 1, 2], [2], [0, 2], [2], [2], [2], [1, 2], [0, 2], [0, 2], [0, 2], [0, 1, 2], [1, 2], [0, 2], [2], [2], [0, 2], [0, 1, 2], [0, 2], [0, 2], [2], [0, 2], [0, 2], [0, 2], [1, 2], [0, 2], [0, 2], [0, 2], [0, 2], [0, 2], [0, 2], [0, 2], [0, 2], [0, 2], [1, 2], [0, 1, 2], [2], [0, 2], [2], [0, 2], [0, 2], [0, 2], [1, 2], [0, 2], [0, 1, 2], [2], [1, 2], [0, 1, 2], [0, 2], [0, 1, 2], [0, 2], [2], [0, 1, 2], [2], [0, 2], [0, 2], [0, 2], [0, 1, 2], [2]]\n"
     ]
    }
   ],
   "source": [
    "categories = ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware']\n",
    "train = fetch_20newsgroups(subset=\"train\", categories=categories)\n",
    "test = fetch_20newsgroups(subset=\"test\", categories=categories)\n",
    "br = BinaryRelevance(train.data)\n",
    "br.set_labels([0,1,2])\n",
    "\n",
    "N = 50\n",
    "train0, train1, train2 = [], [], []\n",
    "for x, t in zip(train.data, train.target):\n",
    "    if t == 0:\n",
    "        train0.append(x)\n",
    "    elif t == 1:\n",
    "        train1.append(x)\n",
    "    elif t == 2:\n",
    "        train2.append(x)\n",
    "train0, train1, tarin2 = train0[:N], train1[:N], train2[:N]\n",
    "\n",
    "negative_x = np.array(train1+train2)\n",
    "np.random.shuffle(negative_x)\n",
    "negative_x = negative_x[:N]\n",
    "br.train(0, train0, negative_x)\n",
    "\n",
    "negative_x = np.array(train0+train2)\n",
    "np.random.shuffle(negative_x)\n",
    "negative_x = negative_x[:N]\n",
    "br.train(1, train1, negative_x)\n",
    "\n",
    "negative_x = np.array(train0+train1)\n",
    "np.random.shuffle(negative_x)\n",
    "negative_x = negative_x[:N]\n",
    "br.train(2, train2, negative_x)\n",
    "\n",
    "y = br.predict(test.data[:100])\n",
    "print(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
